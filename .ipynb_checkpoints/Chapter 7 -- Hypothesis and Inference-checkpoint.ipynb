{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from authorcode.probability import normal_cdf, inverse_normal_cdf\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "under various assumptions, think of statistics as observations of random variables from known distributions, which allows us to make statements about how likely those are to hold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_0: coin is fair\n",
    "\n",
    "H_a: coin is not fair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can approximate bernoulli trials with normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_approximation_to_binomial(n, p):\n",
    "    '''finds Normal mu and sigma correseponding to Binomial(n,p)'''\n",
    "    mu = p * n\n",
    "    sigma = math.sqrt(p * (1 - p) * n)\n",
    "    return mu, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when a RV follows a normal distribution, can use normal_cdf to get probability that realized value lies within/outside interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def normal_cdf(x, mu=0,sigma=1):\n",
      "    return (1 + math.erf((x - mu) / math.sqrt(2) / sigma)) / 2  \n",
      "\n",
      "def inverse_normal_cdf(p, mu=0, sigma=1, tolerance=0.00001):\n",
      "    \"\"\"find approximate inverse using binary search\"\"\"\n",
      "\n",
      "    # if not standard, compute standard and rescale\n",
      "    if mu != 0 or sigma != 1:\n",
      "        return mu + sigma * inverse_normal_cdf(p, tolerance=tolerance)\n",
      "    \n",
      "    low_z, low_p = -10.0, 0            # normal_cdf(-10) is (very close to) 0\n",
      "    hi_z,  hi_p  =  10.0, 1            # normal_cdf(10)  is (very close to) 1\n",
      "    while hi_z - low_z > tolerance:\n",
      "        mid_z = (low_z + hi_z) / 2     # consider the midpoint\n",
      "        mid_p = normal_cdf(mid_z)      # and the cdf's value there\n",
      "        if mid_p < p:\n",
      "            # midpoint is still too low, search above it\n",
      "            low_z, low_p = mid_z, mid_p\n",
      "        elif mid_p > p:\n",
      "            # midpoint is still too high, search below it\n",
      "            hi_z, hi_p = mid_z, mid_p\n",
      "        else:\n",
      "            break\n",
      "\n",
      "    return mid_z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "print inspect.getsource(normal_cdf)\n",
    "print inspect.getsource(inverse_normal_cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "normal_probability_below = normal_cdf\n",
    "\n",
    "def normal_probability_above(lo, mu = 0, sigma = 1):\n",
    "    return 1 - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "def normal_probability_between(lo, hi, mu = 0, sigma = 1):\n",
    "    return normal_cdf(hi, mu, sigma) - normal_cdf(lo, mu, sigma)\n",
    "\n",
    "def normal_probability_outside(lo, hi, mu = 0, sigma = 1):\n",
    "    return 1 - normal_probability_between(lo, hi, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_upper_bound(probability, mu = 0, sigma = 1):\n",
    "    '''returns the z for which P(Z <= z) = probability'''\n",
    "    return inverse_normal_cdf(probability, mu, sigma)\n",
    "\n",
    "def normal_lower_bound(probability, mu = 0, sigma = 1):\n",
    "    '''returns the z for which P(Z >= z) = probability'''\n",
    "    return inverse_normal_cdf(1 - probability, mu, sigma)\n",
    "\n",
    "def normal_two_sided_bounds(probability, mu=0, sigma=1):\n",
    "    \"\"\"returns the symmetric (about the mean) bounds \n",
    "    that contain the specified probability\"\"\"\n",
    "    tail_probability = (1 - probability) / 2\n",
    "\n",
    "    # upper bound should have tail_probability above it\n",
    "    upper_bound = normal_lower_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    # lower bound should have tail_probability below it\n",
    "    lower_bound = normal_upper_bound(tail_probability, mu, sigma)\n",
    "\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "approximation of 1000 coin flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500.0\n",
      "15.8113883008\n"
     ]
    }
   ],
   "source": [
    "mu_0, sigma_0 = normal_approximation_to_binomial(1000, 0.5)\n",
    "print mu_0\n",
    "print sigma_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to make a decision about SIGNIFICANCE\n",
    "\n",
    "Q: How willing are we to make a Type I error (\"false positive\") where we reject H_0 when it's true?\n",
    "\n",
    "usually 1% or 5% (significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(469.01026640487555, 530.9897335951244)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### power: probability of NOT making a Type II error\n",
    "where we fail to reject H_0 when we know it's false\n",
    "\n",
    "knowing merely that H_0 is not true does not give lots of information about the distribution\n",
    "\n",
    "let's check what happens if p is really 0.55 and calculate power\n",
    "\n",
    "95% bounds based on assumption p is 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lo, hi = normal_two_sided_bounds(0.95, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual mu and sigma based on p = 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu_1, sigma_1 = normal_approximation_to_binomial(1000, 0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a type 2 error means we fail to reject null hypothesis which will happen when X is still in our original interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "power 0.886548001295\n"
     ]
    }
   ],
   "source": [
    "# prob of accepting H_0 under actual distribution\n",
    "type_2_probability = normal_probability_between(lo, hi, mu_1, sigma_1) \n",
    "power = 1 - type_2_probability\n",
    "print 'power', power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H_0: coin not biased towards heads (Prop of heads = 0.5)\n",
    "\n",
    "H_a: coin biased towards heads (Prop of heads > 0.5)\n",
    "\n",
    "one-sided test: reject when X much larger than 50, but not when smaller than 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi 526.007358524\n",
      "power 0.936379480331\n"
     ]
    }
   ],
   "source": [
    "hi = normal_upper_bound(0.95, mu_0, sigma_0)\n",
    "print 'hi', hi\n",
    "\n",
    "type_2_probability = normal_probability_below(hi, mu_1, sigma_1)\n",
    "power = 1 - type_2_probability\n",
    "print 'power', power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-values\n",
    "the probability, assuming H_0 is true, that we would see a value at least as extreme as one we observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_sided_p_value(x, mu = 0, sigma = 1):\n",
    "    if x >= mu:\n",
    "        # if x is greater than the mean, the tail is what's greater than x\n",
    "        return 2 * normal_probability_above(x, mu, sigma)\n",
    "    else:\n",
    "        # if x is less than the mean, the tail is what's less than x\n",
    "        return 2 * normal_probability_below(x, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06207721579598857"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(529.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "continuity correction: better estimate of the probability of seeing at least 530 heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extreme_value_count = 0\n",
    "for _ in range(100000):\n",
    "    num_heads = sum(1 if random.random() < 0.5 else 0  # count no. of heads\n",
    "                   for _ in range(1000))               # in 1000 flips\n",
    "    if num_heads >= 530 or num_heads <= 470:           # and count how often\n",
    "        extreme_value_count += 1                       # the no. is extreme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06175\n"
     ]
    }
   ],
   "source": [
    "print extreme_value_count / 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since p-value is greater than 5% significance we don't reject the null\n",
    "\n",
    "if we instead saw 532 heads, the p-val would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.046345287837786575"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(531.5, mu_0, sigma_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is smaller than 5% significance, which means reject the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "upper_p_value = normal_probability_above\n",
    "lower_p_value = normal_probability_below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06062885772582083"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(524.5, mu_0, sigma_0) # do not reject null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04686839508859242"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_p_value(526.5, mu_0, sigma_0) # reject null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make sure data is roughly normally distributed before computing p-values (start with plotting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've been testing hypotheses about the value of heads (probability `p`) which  is a parameter of the unknown heads distribution\n",
    "\n",
    "a third approach is to construct a confidence interval around the parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can get 525 heads implying p = 0.525, but how *confident* can we be about the estimate?\n",
    "\n",
    "Central Limit Theorem tells us that the average of those Bernoulli trials should be approx. normal, with mean `p` and standard: deviation\n",
    "\n",
    "`math.sqrt( p * (1 - p) / 1000)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p_hat = 525 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * ( 1 - p_hat ) / 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4940490278129096, 0.5559509721870904)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since 0.5 is in this 95% confidence interval, we cannot conclude the coin is unfair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5091095927295919, 0.5708904072704082)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_hat = 540 / 1000\n",
    "mu = p_hat\n",
    "sigma = math.sqrt(p_hat * ( 1 - p_hat ) / 1000)\n",
    "normal_two_sided_bounds(0.95, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we saw 540 heads, we can conclude the the coin is unfair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#P-hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46\n"
     ]
    }
   ],
   "source": [
    "def run_experiment():\n",
    "    '''flip a fair coin 1000 times, True = heads, False = tails'''\n",
    "    return [random.random() < 0.5 for _ in range(1000)]\n",
    "\n",
    "def reject_fairness(experiment):\n",
    "    '''reject at 5% significance level'''\n",
    "    num_heads = len([flip for flip in experiment if flip])\n",
    "    return num_heads < 469 or num_heads > 531\n",
    "\n",
    "random.seed(0)\n",
    "experiments = [run_experiment() for _ in range(1000)]\n",
    "num_rejections = len([experiment\n",
    "                     for experiment in experiments\n",
    "                     if reject_fairness(experiment)])\n",
    "\n",
    "print num_rejections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you're setting out to find \"significant\" results, you usually can\n",
    "\n",
    "test enough hypotheses against your data set and one of them will almost certainly appear significant\n",
    "\n",
    "remove the right outliers and you can probably get your p-value below 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for good science:\n",
    "* determine hypotheses before looking at data\n",
    "* clean data without hypotheses in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Running an A/B test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Use statistical inference to check which ad is better, A or B\n",
    "\n",
    "* N_A people see ad A, n_A click\n",
    "* N_B people see ad B, n_B click\n",
    "\n",
    "if N_A is large, we know that n_A / N_A is approximately a normal random variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimated_parameters(N, n):\n",
    "    p = n / N\n",
    "    sigma = math.sqrt(p * (1 - p) / N)\n",
    "    return p, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we assume those two normals are independent, which seems reasonable, then their difference should also be normal\n",
    "\n",
    "* mean of a normal difference: p_B - p_A\n",
    "* std dev of a normal difference: sqrt( sigma_A ^ 2 + sigma_B ^ 2 )\n",
    "\n",
    "this means we can test the null that the difference is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def a_b_test_statistic(N_A, n_A, N_B, n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A) / math.sqrt(sigma_A ** 2 + sigma_B ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if \"tastes great\" gets 200 clicks / 1000 views and \"less bias\" gets 180 clicks out of 1000 views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1403464899\n"
     ]
    }
   ],
   "source": [
    "z = a_b_test_statistic(1000, 200, 1000, 180)\n",
    "print z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.254141976542236"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sided_p_value(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003189699706216853"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = a_b_test_statistic(1000, 200, 1000, 150)\n",
    "two_sided_p_value(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The procedures we've looked at have involved making probability statements about our **tests**: \"there's only a 3% chance you'd observe such an extreme statistic if our null hypothesis were true.\"\n",
    "\n",
    "An alternative approach to inference involves treating the unknown parameters themselves as random variables. The analyst starts with a *prior distribution* for the parameters and then uses the observed data and Bayes's Theorem to get an updated *posterior distribution* for the parameters.\n",
    "\n",
    "Rather than make probability judgments about the tests, you make probability judgements about the parameters themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the unknown param is a probability, we often use a prior from the Beta distribution, which puts all its probabilities between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def B(alpha, beta):\n",
    "    ''' a normalizing constant so that the total probability is 1 '''\n",
    "    return math.gamma(alpha) * math.gamma(beta) / math.gamma(alpha + beta)\n",
    "\n",
    "def beta_pdf(x, alpha, beta):\n",
    "    ''' probability of seeing that value '''\n",
    "    if x < 0 or x > 1:\n",
    "        return 0\n",
    "    return x ** (alpha - 1) * (1 - x) ** (beta - 1) / B(alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generally speaking, this dist. centers its weight at `alpha / (alpha + beta)` and the larger alpha and beta the tighter the distribution is\n",
    "\n",
    "if alpha and beta are both 1 it's just the uniform distribution, centered at 0.5, very dispersed\n",
    "\n",
    "if alpha is much larger than beta, most of the weight is near 1\n",
    "\n",
    "if alpha much smaller than beta, most of the weight near 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "setting the prior:\n",
    "* if we don't want to take a stand on fairness of the coin, we can set both alpha and beta equal to one\n",
    "* if we have a strong belief it lands heads 55% of the time, we choose alpha equals 55 and beta equals 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then we flip our coin a bunch of times, see h heads and t tails\n",
    "\n",
    "Bayes's Theorem tells us that the posterior distribution of p is again a Beta distribution with params `alpha + h` and `beta + t`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refuse to take a stand on the coin's fairness\n",
    "* Uniform prior: Beta(1,1) centered at 0.5\n",
    "* Flip coin 10 times, get 3 heads\n",
    "* Posterior: Beta(4,8) centered at 0.33\n",
    "\n",
    "Believe coin is fair\n",
    "* Prior: Beta(20,20) centered at 0.5\n",
    "* Flip coin 10 times, get 3 heads\n",
    "* Posterior: Beta(23,27) centered at 0.46\n",
    "\n",
    "Believe coin flips heads 75% of the time\n",
    "* Prior: Beta(30,10) centered at 0.5\n",
    "* Flip coin 10 times, get 3 heads\n",
    "* Posterior: Beta(33,17) centered at 0.66\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you flipped the coin more and more times, the prior would matter less and less until eventually you'd have nearly the same posterior distribution no matter what prior you started with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This allows us to make probability statements about hypotheses:\n",
    "* Bayesian: Based on the prior and the observed data, there is only a 5% likelihood the coin's heads probability is between 49% and 51%\n",
    "* Hypothesis test: If the coin were fair we would expect to observe data so extreme only 5% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

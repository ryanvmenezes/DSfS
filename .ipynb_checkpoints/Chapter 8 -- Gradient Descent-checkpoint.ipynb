{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter\n",
    "from authorcode.linear_algebra import distance, vector_subtract, scalar_multiply\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to find a model that minimizes error or maximizes likelihood of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sum_of_squares(v):\n",
    "    '''computes the sum of squared elements in v'''\n",
    "    return sum(v_i ** 2 for v_i in v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to find v that produces largest/smallest value\n",
    "\n",
    "**gradient** gives the input direction in which the function most quickly increases\n",
    "\n",
    "pick a random starting point, compute the gradient, take a small step in the direction of the gradient, repeat\n",
    "\n",
    "if function has unique global minimum, this procedure likely to find it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating the gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if f is a function of one variable, its derivative at point x measures how f(x) changes when we make a very small change to x\n",
    "\n",
    "it is defined as the limit of the difference quotients as h approaches 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def difference_quotient(f, x, h):\n",
    "    return (f(x+h) - f(x)) / h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "derivative is the slope of the tangent line at $x, f(x)$, while difference quotient is the slope of the not-quiet tangent line that runs through $((x+h), f(x+h))$\n",
    "\n",
    "$$ \\frac{f(x+h) - f(x)}{h}$$\n",
    "\n",
    "as h gets smaller the estimation of the tangent line gets better\n",
    "\n",
    "for many functions it is easy to calculate derivatives\n",
    "\n",
    "$$ \\int x^2 = 2x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can't take limits in python but we can estimate derivatives by evaluating the difference quotient for a very small e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    return x*x\n",
    "\n",
    "def derivative(x):\n",
    "    return 2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "derivative_estimate =  lambda x: difference_quotient(square, x, h=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEACAYAAABWLgY0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa6f00f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot to show they're basically the same\n",
    "import matplotlib.pyplot as plt\n",
    "x = range(-10,10)\n",
    "plt.plot(x, map(derivative, x), 'rx')           # red  x\n",
    "plt.plot(x, map(derivative_estimate, x), 'b+')  # blue +\n",
    "plt.show()                                      # purple *, hopefully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f has multiple partial derivatives, each indicating how f changes when we make small changes in just one of the input variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can calculate its $i$th partial derivative by treating it as a function of just its $i$th variable, holding the other variables fixed, and calculate the gradient the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_differences_quotient(f, v, i, h):\n",
    "    '''compute the ith partial difference quotient of f at v'''\n",
    "    w = [v_j + (h if j == i else 0)\n",
    "        for j, v_j in enumerate(v)]\n",
    "    return (f(w) - f(v)) / h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimate_gradient(f, v, h = 0.00001):\n",
    "    return [partial_differences_quotient(f, v, i, h)\n",
    "           for i, _ in enumerate(v)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is computationally expensive, estimate_gradient has to evaluate f on 2 times the length of v inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
